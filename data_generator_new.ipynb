{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.impute import KNNImputer\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(\"data/data_by_table/baseline.csv\")\n",
    "vitalsign_df = pd.read_csv(\"data/data_by_table/mimiciv_derived_vitalsign_new.csv\")\n",
    "labevents_df = pd.read_csv(\"data/data_by_table/mimiciv_hosp_labevents.csv\")\n",
    "cohort_subject_id_stay_id_df = pd.read_csv(\"data/data_by_table/cohort_subject_id_stay_id.csv\")\n",
    "ground_truth_df = pd.read_csv(\"data/data_by_table/ground_truth.csv\")\n",
    "ventilator_setting_df = pd.read_csv(\"data/paper_data/ven_setting.csv\")\n",
    "GCS_df = pd.read_csv(\"data/paper_data/GCS.csv\")\n",
    "anion_df = pd.read_csv(\"data/paper_data/Anion.csv\")\n",
    "urine_df = pd.read_csv(\"data/paper_data/urine_output.csv\")\n",
    "label_df = pd.read_csv(\"data/data_by_table/ground_truth.csv\")\n",
    "baseline_df.replace('___', pd.NA, inplace=True)\n",
    "vitalsign_df.replace('___', pd.NA, inplace=True)\n",
    "labevents_df.replace('___', pd.NA, inplace=True)\n",
    "cohort_subject_id_stay_id_df.replace('___', pd.NA, inplace=True)\n",
    "ventilator_setting_df.replace('___', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2835    1\n",
      "2836    1\n",
      "2837    1\n",
      "2838    1\n",
      "2839    1\n",
      "Name: label, Length: 2840, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(label_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_template(stay_id, endtime):\n",
    "    end_time = pd.to_datetime(endtime).floor('H')\n",
    "    time_intervals = [end_time - timedelta(hours=i) for i in range(24)]\n",
    "    df = pd.DataFrame(time_intervals, columns=['charttime'])\n",
    "    df['stay_id'] = stay_id \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_template(ground_truth_df):\n",
    "    data_template = pd.DataFrame()\n",
    "    for index, row in ground_truth_df.iterrows():\n",
    "        data_now = generate_df_template(row['stay_id'],row['endtime'])\n",
    "        data_template = pd.concat([data_template, data_now], ignore_index=False)\n",
    "    return data_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "    df = df.sort_values(by=['stay_id', 'charttime'])\n",
    "    df = df.set_index('charttime')\n",
    "    df_resampled = df.groupby('stay_id').resample('H').max()\n",
    "    for col in df.columns:\n",
    "        if(col != 'stay_id' and col != 'subject_id' and col != 'charttime'):\n",
    "            df_resampled[col] = df_resampled[col].groupby('stay_id').fillna(method='ffill')\n",
    "            df_resampled[col] = df_resampled[col].groupby('stay_id').fillna(method='bfill')\n",
    "    df_resampled = df_resampled.drop(columns='stay_id')\n",
    "    df_resampled = df_resampled.reset_index()\n",
    "    for col in df.columns:\n",
    "        if col == 'subject_id':\n",
    "            df_resampled = df_resampled.drop(columns='subject_id')\n",
    "        if col == 'hadm_id':\n",
    "            df_resampled = df_resampled.drop(columns='hadm_id')\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_merge(data_all, df_target, ground_truth_df):\n",
    "    template = generate_all_template(ground_truth_df)\n",
    "    df_target = fill_na(df_target)\n",
    "    df = pd.merge(df_target, template, how='outer', on=['stay_id','charttime'])\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "    df = df.sort_values(by=['stay_id', 'charttime'])\n",
    "    df = df.set_index('charttime')\n",
    "    df_resampled = df.groupby('stay_id').resample('H').max()\n",
    "    for col in df.columns:\n",
    "        if(col != 'stay_id' and col != 'subject_id' and col != 'charttime'):\n",
    "            df_resampled[col] = df_resampled[col].groupby('stay_id').fillna(method='ffill')\n",
    "            df_resampled[col] = df_resampled[col].groupby('stay_id').fillna(method='bfill')\n",
    "    df_resampled = df_resampled.drop(columns='stay_id')\n",
    "    df_resampled = df_resampled.reset_index()\n",
    "    df = pd.merge(data_all,df_resampled, how='inner', on=['stay_id','charttime'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    if df.isna().any().any():\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "def output_id_missing(flag_data_df,data_df):\n",
    "    ass_hole = []\n",
    "    for index, row in flag_data_df.iterrows():\n",
    "        id_df = data_df[data_df['stay_id'] == row['stay_id']]\n",
    "        if check_missing_values(id_df):\n",
    "            ass_hole.append(row['stay_id'])\n",
    "    return ass_hole\n",
    "\n",
    "def output_id_not_missing(flag_data_df,data_df):\n",
    "    ass_hole = []\n",
    "    for index, row in flag_data_df.iterrows():\n",
    "        id_df = data_df[data_df['stay_id'] == row['stay_id']]\n",
    "        if not check_missing_values(id_df):\n",
    "            ass_hole.append(row['stay_id'])\n",
    "    return ass_hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_id(df,stay_id, flag, r_v, dod):\n",
    "    selected_data = df[df['stay_id'] == stay_id]\n",
    "    selected_data['label'] = flag\n",
    "    if np.isnan(r_v):\n",
    "        selected_data['Rev_h'] = -1000\n",
    "    else:\n",
    "         selected_data['Rev_h'] = r_v\n",
    "    if np.isnan(dod):\n",
    "        selected_data['dod_h'] = -1000\n",
    "    else:\n",
    "         selected_data['dod_h'] = dod\n",
    "    selected_data = selected_data.sort_values(by=['stay_id', 'charttime'])\n",
    "    return selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(df, df_label):\n",
    "    cancate_data = pd.DataFrame()\n",
    "    for index, row in df_label.iterrows():\n",
    "        data_now = add_label_id(df,row['stay_id'],row['label'], row['re_vent_time_diff'], row['weaning_till_dod_hr'])\n",
    "        cancate_data = pd.concat([cancate_data, data_now], ignore_index=False)\n",
    "    return cancate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline_df, ventilator_setting_df, vitalsign_df, labevents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/mbl70bkn0sjgq2yfg5rc6xp40000gn/T/ipykernel_1307/4195987250.py:5: FutureWarning: Dropping invalid columns in DataFrameGroupBy.max is deprecated. In a future version, a TypeError will be raised. Before calling .max, select only columns which should be valid for the function.\n",
      "  df_resampled = df.groupby('stay_id').resample('H').max()\n"
     ]
    }
   ],
   "source": [
    "data_template = generate_all_template(ground_truth_df)\n",
    "ventilator_setting_df_24 = fill_and_merge(data_template, ventilator_setting_df, ground_truth_df)\n",
    "print(\"ventilator_setting_df_24 finish\")\n",
    "labevents_df_24 = fill_and_merge(data_template, labevents_df, ground_truth_df)\n",
    "print(\"labevents_df_24 finish\")\n",
    "vitalsign_df_24 = fill_and_merge(data_template, vitalsign_df, ground_truth_df)\n",
    "print(\"vitalsign_df_24 finish\")\n",
    "GCS_df_24 = fill_and_merge(data_template, GCS_df, ground_truth_df)\n",
    "print(\"GCS_df_24 finish\")\n",
    "anion_df_24 = fill_and_merge(data_template, anion_df, ground_truth_df)\n",
    "print(\"anion_df_24 finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "baseline_df_p = baseline_df \n",
    "baseline_df_p[['height_cm', 'weight_kg']] = imputer.fit_transform(baseline_df_p[['height_cm', 'weight_kg']])\n",
    "baseline_df_p['height_cm'].fillna(baseline_df_p.groupby('gender')['height_cm'].transform('mean'), inplace=True)\n",
    "baseline_df_p['weight_kg'].fillna(baseline_df_p.groupby('gender')['weight_kg'].transform('mean'), inplace=True)\n",
    "baseline_df_p = baseline_df_p.drop(columns=['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(labevents_df_24, vitalsign_df_24, on=['stay_id', 'charttime'], how='inner')\n",
    "merged_df = pd.merge(merged_df, labevents_df_24, on=['stay_id', 'charttime'], how='inner')\n",
    "merged_df = pd.merge(merged_df, ventilator_setting_df_24, on=['stay_id', 'charttime'], how='inner')\n",
    "merged_df = pd.merge(merged_df, GCS_df_24, on=['stay_id', 'charttime'], how='inner')\n",
    "#merged_df = pd.merge(merged_df, anion_df_24, on=['stay_id', 'charttime'], how='inner')\n",
    "merged_df = pd.merge(merged_df, baseline_df, on=['stay_id'], how='inner')\n",
    "merged_df = merged_df.drop(columns=['subject_id', 'hadm_id', 'charttime_1', 'ventilator_type'])\n",
    "final_data = add_label(merged_df, ground_truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df_new = pd.DataFrame()\n",
    "label_df_new['label'] = label_df['label']\n",
    "label_df_new['stay_id'] = label_df['stay_id']\n",
    "merged_df = pd.merge(merged_df, label_df_new, on=['stay_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"./data/data_by_table/pre_24h_data_v5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
